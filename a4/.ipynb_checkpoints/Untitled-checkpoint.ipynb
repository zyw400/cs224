{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sents = [[\"a\",\"b\",\"c\"],[\"c\"],[\"s\",\"s\"]]\n",
    "pad_token = \"-\"\n",
    "\n",
    "\n",
    "sents_padded = []\n",
    "\n",
    "max_length = max([len(sent) for sent in sents])\n",
    "for sent in sents:\n",
    "    sents_padded.append(sent + (max_length-len(sent)) * [pad_token])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['a', 'b', 'c'], ['c', '-', '-'], ['s', 's', '-']]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sents_padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 4])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "(src_len, b) = (3,4)\n",
    "source_padded = torch.tensor([[1,2,3,4],[2,2,2,2],[1,1,1,1]])\n",
    "source_padded.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 4, 5])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rm = nn.Embedding(30, 5)\n",
    "rm(source_padded).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "(b, src_len, h) = (2,3,8)\n",
    "x = torch.randn(2,3,8)\n",
    "# x.permute(1, 0, 2).size()\n",
    "att_projection = nn.Linear(8, 4, bias = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 4])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "att_projection(x).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_x = []\n",
    "for y in torch.split(x,split_size_or_sections=1):\n",
    "    new_x.append(torch.squeeze(y, dim=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 8])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_x[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 16])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat((new_x[0], new_x[0]), 1).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 8])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = (x[1],x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.6352, -0.3001, -0.7635,  0.1438, -0.0461, -0.4254, -1.6635,  0.7414],\n",
       "        [-0.0682, -0.4322, -1.3447,  0.5542,  0.4735, -0.3836,  1.3751,  1.5927],\n",
       "        [-2.0686, -1.3427, -0.0484,  1.0411,  2.0111, -1.9386, -0.5779,  0.2240]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(c,d)=a\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.6352, -0.3001, -0.7635,  0.1438, -0.0461, -0.4254, -1.6635,  0.7414],\n",
       "        [-0.0682, -0.4322, -1.3447,  0.5542,  0.4735, -0.3836,  1.3751,  1.5927],\n",
       "        [-2.0686, -1.3427, -0.0484,  1.0411,  2.0111, -1.9386, -0.5779,  0.2240]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = nn.LSTMCell(10, 20)\n",
    "s = rnn(torch.randn(2,10))\n",
    "hx, cx = s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1943, -0.0581,  0.0647, -0.0248, -0.0687, -0.2184, -0.1143, -0.1374,\n",
       "         -0.1806,  0.0601,  0.1132, -0.0116, -0.0417,  0.0818,  0.0824, -0.2109,\n",
       "          0.2122,  0.1127, -0.0032,  0.0843],\n",
       "        [-0.1566,  0.0667,  0.0073, -0.0655,  0.0126, -0.1735,  0.1193,  0.2555,\n",
       "          0.1383,  0.0894,  0.0585,  0.0279,  0.0092,  0.0164,  0.0452,  0.0141,\n",
       "          0.0622, -0.1020,  0.0461, -0.1525]], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.3521, -0.1450,  0.1275, -0.0480, -0.1512, -0.3637, -0.2091, -0.2514,\n",
       "         -0.3259,  0.1413,  0.1722, -0.0216, -0.1182,  0.2440,  0.3095, -0.4977,\n",
       "          0.3549,  0.2244, -0.0053,  0.1930],\n",
       "        [-0.2749,  0.1088,  0.0188, -0.1073,  0.0349, -0.3360,  0.1881,  0.3522,\n",
       "          0.2063,  0.2232,  0.1639,  0.0904,  0.0231,  0.0382,  0.1128,  0.0218,\n",
       "          0.1205, -0.2443,  0.0782, -0.2549]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.1943, -0.0581,  0.0647, -0.0248, -0.0687, -0.2184, -0.1143, -0.1374,\n",
       "          -0.1806,  0.0601,  0.1132, -0.0116, -0.0417,  0.0818,  0.0824, -0.2109,\n",
       "           0.2122,  0.1127, -0.0032,  0.0843],\n",
       "         [-0.1566,  0.0667,  0.0073, -0.0655,  0.0126, -0.1735,  0.1193,  0.2555,\n",
       "           0.1383,  0.0894,  0.0585,  0.0279,  0.0092,  0.0164,  0.0452,  0.0141,\n",
       "           0.0622, -0.1020,  0.0461, -0.1525]], grad_fn=<MulBackward0>),\n",
       " tensor([[-0.3521, -0.1450,  0.1275, -0.0480, -0.1512, -0.3637, -0.2091, -0.2514,\n",
       "          -0.3259,  0.1413,  0.1722, -0.0216, -0.1182,  0.2440,  0.3095, -0.4977,\n",
       "           0.3549,  0.2244, -0.0053,  0.1930],\n",
       "         [-0.2749,  0.1088,  0.0188, -0.1073,  0.0349, -0.3360,  0.1881,  0.3522,\n",
       "           0.2063,  0.2232,  0.1639,  0.0904,  0.0231,  0.0382,  0.1128,  0.0218,\n",
       "           0.1205, -0.2443,  0.0782, -0.2549]], grad_fn=<AddBackward0>))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 8])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[1].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = torch.unsqueeze(x[1],2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 8])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.squeeze(x1,2).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "(b, src_len, h) = (3,2,4)\n",
    "enc_hiddens_proj = torch.ones(b, src_len, h)\n",
    "dec_hidden = torch.tensor([[1,2,3,4],[0,1,0,1],[2,1,0,1.0]])\n",
    "e_t = torch.squeeze(torch.bmm(enc_hiddens_proj, torch.unsqueeze(dec_hidden,2)),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_hiddens = torch.ones(b, src_len, 2 * h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e_t.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 1., 0., 1.])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i_m = 0\n",
    "batch_no = 1\n",
    "\n",
    "dec_hidden[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1., 1.])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_hiddens_proj[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e_t[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yiwzh-mac/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 8])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "F.softmax(x).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 8])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 8, 3])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.permute([0,2,1]).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yiwzh-mac/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "alpha_t = F.softmax(e_t)\n",
    "a_t = torch.squeeze(torch.bmm(enc_hiddens.permute([0,2,1]), \n",
    "                              torch.unsqueeze(alpha_t,2)),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 8])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_t.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.size()\n",
    "U_t = torch.cat([dec_hidden, a_t], dim=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 12])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "U_t.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
